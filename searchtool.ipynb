{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "class SimpleSearchEngine:\n",
    "    def __init__(self, documents, preprocess=False):\n",
    "        self.preprocess = preprocess\n",
    "        if preprocess:\n",
    "            self.stop_words = set(stopwords.words('english'))\n",
    "            self.stemmer = PorterStemmer()\n",
    "            documents = [self.preprocess_text(doc) for doc in documents]\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.document_vectors = self.vectorizer.fit_transform(documents)\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(text)\n",
    "        # Convert to lowercase and remove punctuation\n",
    "        tokens = [token.lower() for token in tokens if token not in string.punctuation]\n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        # Stem the words\n",
    "        tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def search(self, query, top_k=5, min_similarity=0.0):\n",
    "        if self.preprocess:\n",
    "            query = self.preprocess_text(query)\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_vector, self.document_vectors).flatten()\n",
    "        # Filter results based on minimum similarity threshold\n",
    "        results = [(idx, similarity) for idx, similarity in enumerate(similarities) if similarity >= min_similarity]\n",
    "        # Sort results by similarity score\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        # Return the top k results\n",
    "        return results[:top_k]\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"The quick brown fox is fast and agile.\",\n",
    "    \"The lazy dog is slow and sleepy.\",\n",
    "    \"The cat is curious and playful.\",\n",
    "    \"The dog and the cat are friends.\",\n",
    "    \"The fox, the dog, and the cat are playing together.\"\n",
    "]\n",
    "\n",
    "# Initialize the search engine with the documents\n",
    "search_engine = SimpleSearchEngine(documents, preprocess=True)\n",
    "\n",
    "# Perform a search\n",
    "query = \"quick fox\"\n",
    "top_k = 3\n",
    "min_similarity = 0.1\n",
    "results = search_engine.search(query, top_k, min_similarity)\n",
    "\n",
    "# Display the search results\n",
    "print(\"Search results for query:\", query)\n",
    "for i, (idx, similarity) in enumerate(results):\n",
    "    print(f\"Rank {i+1} (Similarity: {similarity:.2f}): {documents[idx]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
